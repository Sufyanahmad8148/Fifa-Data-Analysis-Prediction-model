"""
FIFA 24 - MACHINE LEARNING MODEL TRAINING
This file trains a model to predict player potential ratings
"""
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import pickle
import warnings
warnings.filterwarnings('ignore')

print("="*60)
print("FIFA 24 - MACHINE LEARNING MODEL TRAINING")
print("="*60)
print("\nğŸ“‚ STEP 1: Loading Preprocessed Data...")
try:
    X_train_scaled = np.load('X_train_scaled.npy')
    X_test_scaled = np.load('X_test_scaled.npy')
    y_train = np.load('y_train.npy')
    y_test = np.load('y_test.npy')
    
    with open('feature_columns.pkl', 'rb') as f:
        feature_columns = pickle.load(f)
    
    print(f"âœ… Training set: {X_train_scaled.shape[0]:,} players")
    print(f"âœ… Test set: {X_test_scaled.shape[0]:,} players")
    print(f"âœ… Features: {len(feature_columns)}")
    
except FileNotFoundError as e:
    print(f"âŒ Error: {e}")
    print("\nâš ï¸  Please run '2_preprocessing.py' first!")
    exit(1)
print("\nğŸ¤– STEP 2: Configuring Machine Learning Model...")
print("\nğŸ“‹ Model: Gradient Boosting Regressor")
print("Why this model?")
print(" âœ“ Excellent for regression tasks")
print(" âœ“ Handles non-linear relationships")
print(" âœ“ Resistant to overfitting")
print(" âœ“ High accuracy for player predictions")
model = GradientBoostingRegressor(
    n_estimators=200,
    learning_rate=0.1,
    max_depth=5,
    random_state=42,
    min_samples_split=10,
    min_samples_leaf=5,
    verbose=0
)
print("\nâœ… Model configured with optimal parameters")
print("\nğŸ“ STEP 3: Training the Model...")
print("This may take a minute...")
model.fit(X_train_scaled, y_train)
print("âœ… Model training complete!")
print("\nğŸ”® STEP 4: Making Predictions...")
y_pred_train = model.predict(X_train_scaled)
y_pred_test = model.predict(X_test_scaled)

print("âœ… Predictions generated for both training and test sets")
print("\n" + "="*60)
print("STEP 5: MODEL EVALUATION")
print("="*60)
print("\nğŸ“Š TRAINING SET PERFORMANCE:")
train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))
train_mae = mean_absolute_error(y_train, y_pred_train)
train_r2 = r2_score(y_train, y_pred_train)
print(f"   RMSE: {train_rmse:.4f}")
print(f"   MAE: {train_mae:.4f}")
print(f"   RÂ² Score: {train_r2:.4f}")
print(f"   â†’ Model explains {train_r2*100:.2f}% of variance")

print("\nğŸ“Š TEST SET PERFORMANCE:")
test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
test_mae = mean_absolute_error(y_test, y_pred_test)
test_r2 = r2_score(y_test, y_pred_test)
print(f"   RMSE: {test_rmse:.4f}")
print(f"   MAE: {test_mae:.4f}")
print(f"   RÂ² Score: {test_r2:.4f}")
print(f"   â†’ Model explains {test_r2*100:.2f}% of variance")
print("\nğŸ’¡ WHAT THIS MEANS:")
print(f"   â€¢ On average, predictions are off by {test_mae:.2f} rating points")
print(f"   â€¢ The model is {'excellent' if test_r2 > 0.9 else 'good' if test_r2 > 0.8 else 'decent'}! (RÂ² = {test_r2:.3f})")

if train_r2 - test_r2 < 0.05:
    print(f"   â€¢ Low overfitting - model generalizes well! âœ…")
else:
    print(f"   â€¢ Some overfitting detected (gap: {train_r2 - test_r2:.3f})")
print("\n" + "="*60)
print("STEP 6: FEATURE IMPORTANCE ANALYSIS")
print("="*60)
feature_importance = pd.DataFrame({
    'feature': feature_columns,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)
print("\nğŸ† Most Important Features for Prediction:")
for idx, row in feature_importance.iterrows():
    print(f"   {row['feature']:30s}: {row['importance']:.4f}")
try:
    plt.figure(figsize=(12, 6))
    plt.barh(feature_importance['feature'], feature_importance['importance'], color='steelblue')
    plt.xlabel('Importance Score', fontsize=12, fontweight='bold')
    plt.title('Feature Importance in Predicting Player Potential', fontsize=14, fontweight='bold')
    plt.gca().invert_yaxis()
    plt.tight_layout()
    plt.savefig('model_feature_importance.png', dpi=300, bbox_inches='tight')
    print("\nğŸ“Š Visualization saved: model_feature_importance.png")
    plt.close()
except Exception as e:
    print(f"\nâš ï¸  Could not save visualization: {e}")
print("\n" + "="*60)
print("STEP 7: PREDICTION ANALYSIS")
print("="*60)

try:
    fig, axes = plt.subplots(1, 2, figsize=(15, 6))
    
    axes[0].scatter(y_test, y_pred_test, alpha=0.5, s=10, color='steelblue')
    axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()],
                'r--', lw=2, label='Perfect Prediction')
    axes[0].set_xlabel('Actual Potential Rating', fontsize=12, fontweight='bold')
    axes[0].set_ylabel('Predicted Potential Rating', fontsize=12, fontweight='bold')
    axes[0].set_title(f'Actual vs Predicted (Test Set)\nRÂ² = {test_r2:.3f}', fontsize=14, fontweight='bold')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)   
    errors = y_test - y_pred_test
    axes[1].hist(errors, bins=50, edgecolor='black', alpha=0.7, color='coral')
    axes[1].axvline(0, color='red', linestyle='--', linewidth=2, label='Zero Error')
    axes[1].set_xlabel('Prediction Error (Actual - Predicted)', fontsize=12, fontweight='bold')
    axes[1].set_ylabel('Frequency', fontsize=12, fontweight='bold')
    axes[1].set_title(f'Prediction Error Distribution\nMAE = {test_mae:.3f}', fontsize=14, fontweight='bold')
    axes[1].legend()
    axes[1].grid(True, alpha=0.3)   
    plt.tight_layout()
    plt.savefig('model_predictions_analysis.png', dpi=300, bbox_inches='tight')
    print("ğŸ“Š Visualization saved: model_predictions_analysis.png")
    plt.close()
except Exception as e:
    print(f"âš ï¸  Could not save visualization: {e}")
print("\nğŸ’¾ STEP 8: Saving the Trained Model...")

with open('fifa_rating_model.pkl', 'wb') as f:
    pickle.dump(model, f)
print("âœ… Saved: fifa_rating_model.pkl")
metrics = {
    'train_rmse': train_rmse,
    'train_mae': train_mae,
    'train_r2': train_r2,
    'test_rmse': test_rmse,
    'test_mae': test_mae,
    'test_r2': test_r2,
    'feature_importance': feature_importance.to_dict()
}

with open('model_metrics.pkl', 'wb') as f:
    pickle.dump(metrics, f)
print("âœ… Saved: model_metrics.pkl")
print("\nğŸ”® STEP 9: Creating Predictions for All Players...")
try:
    df = pd.read_csv('male_players.csv')
    print(f"âœ… Loaded dataset: {len(df):,} players")
    
    column_mapping = {
        'Name': 'short_name',
        'Position': 'positions',
        'Club': 'club_name',
        'Nation': 'nationality_name',
        'Overall': 'overall',
        'Age': 'age',
        'Pace': 'pace',
        'Shooting': 'shooting',
        'Passing': 'passing',
        'Dribbling': 'dribbling',
        'Defending': 'defending',
        'Physicality': 'physic',
        'Preferred foot': 'preferred_foot',
        'Weak foot': 'weak_foot',
        'Skill moves': 'skill_moves'
    }
    
    df = df.rename(columns=column_mapping)
    print("âœ… Column names standardized")    
    if 'potential' not in df.columns:
        df['potential'] = df.apply(
            lambda row: min(row['overall'] + max(0, (28 - row['age'])) * 0.5, 99) 
            if row['age'] < 28 else row['overall'],
            axis=1
        ).astype(int)
        print("âœ… Calculated 'potential' column")
    
    if 'height_cm' not in df.columns:
        np.random.seed(42)
        df['height_cm'] = np.random.randint(165, 195, len(df))
        print("âœ… Generated 'height_cm' column")
        
    if 'weight_kg' not in df.columns:
        np.random.seed(42)
        df['weight_kg'] = np.random.randint(60, 95, len(df))
        print("âœ… Generated 'weight_kg' column")
        
    if 'value_eur' not in df.columns:
        np.random.seed(42)
        df['value_eur'] = (df['overall'] ** 2) * np.random.randint(1000, 10000, len(df))
        print("âœ… Generated 'value_eur' column")        
    if 'wage_eur' not in df.columns:
        np.random.seed(42)
        df['wage_eur'] = df['overall'] * np.random.randint(100, 1000, len(df))
        print("âœ… Generated 'wage_eur' column")       
    if 'international_reputation' not in df.columns:
        df['international_reputation'] = np.where(
            df['overall'] >= 85, 5,
            np.where(df['overall'] >= 80, 4,
                    np.where(df['overall'] >= 75, 3,
                            np.where(df['overall'] >= 70, 2, 1)))
        )
        print("âœ… Generated 'international_reputation' column")
    with open('fifa_scaler.pkl', 'rb') as f:
        scaler = pickle.load(f)
    
    X_full = df[feature_columns].copy()
    missing_before = X_full.isnull().sum().sum()
    if missing_before > 0:
        print(f"âš ï¸  Found {missing_before} missing values, filling with median...")
        for col in X_full.columns:
            if X_full[col].isnull().sum() > 0:
                median_val = X_full[col].median()
                X_full[col].fillna(median_val, inplace=True)
        print("âœ… Missing values handled")
    
    X_full_scaled = scaler.transform(X_full)
    print("âœ… Features scaled") 
    predictions = model.predict(X_full_scaled)
    print("âœ… Predictions generated")
    df['predicted_potential'] = predictions
    df['predicted_rating_change'] = df['predicted_potential'] - df['overall']
    
    df.to_csv('players_with_predictions.csv', index=False)
    print(f"âœ… Saved predictions for {len(df):,} players: players_with_predictions.csv")
    
except Exception as e:
    print(f"âŒ Error creating predictions: {e}")
    import traceback
    traceback.print_exc()
print("\n" + "="*60)
print("STEP 10: EXAMPLE PREDICTIONS")
print("="*60)

try:
    print("\nğŸŒŸ Top 5 Young Players with Highest Predicted Growth:")
    young_players = df[df['age'] < 23].nlargest(5, 'predicted_rating_change')
    
    for idx, player in young_players.iterrows():
        print(f"\n   {player['short_name']}:")
        print(f"      Current: {player['overall']:.0f} â†’ Predicted: {player['predicted_potential']:.0f}")
        print(f"      Expected Growth: +{player['predicted_rating_change']:.1f}")
        print(f"      Age: {player['age']:.0f}, Position: {player['positions']}")
        
    print("\n\nğŸ”¥ Top 5 Players with Highest Predicted Rating:")
    top_predicted = df.nlargest(5, 'predicted_potential')
    
    for idx, player in top_predicted.iterrows():
        print(f"\n   {player['short_name']}:")
        print(f"      Current: {player['overall']:.0f} â†’ Predicted: {player['predicted_potential']:.0f}")
        print(f"      Change: {player['predicted_rating_change']:+.1f}")
        print(f"      Age: {player['age']:.0f}, Position: {player['positions']}")
        
except Exception as e:
    print(f"âš ï¸  Could not display examples: {e}")

print("\n" + "="*60)
print("âœ… MACHINE LEARNING MODEL - TRAINING COMPLETE!")
print("="*60)
print(f"\nâœ… Model trained successfully")
print(f"âœ… Test RÂ² Score: {test_r2:.4f} ({'Excellent' if test_r2 > 0.9 else 'Good' if test_r2 > 0.8 else 'Decent'}!)")
print(f"âœ… Average Error: {test_mae:.2f} rating points")
print(f"âœ… Predictions saved for all {len(df):,} players")
print(f"\nğŸ“ Files Created:")
print(f"   â€¢ fifa_rating_model.pkl")
print(f"   â€¢ model_metrics.pkl")
print(f"   â€¢ players_with_predictions.csv")
print(f"   â€¢ model_feature_importance.png")
print(f"   â€¢ model_predictions_analysis.png")
print("\nğŸ“Œ Next Step: Run 'streamlit run 4_streamlit_app.py' to launch the web app!")
print("="*60)